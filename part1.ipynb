{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vital Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_db = pd.read_csv('GiveMeSomeCredit/cs-training.csv')\n",
    "dataset_np = dataset_db.to_numpy()\n",
    "data = np.delete(dataset_np,0,1)\n",
    "\n",
    "test_db = pd.read_csv('GiveMeSomeCredit/cs-test.csv')\n",
    "test_np = test_db.to_numpy()\n",
    "test = np.delete(test_np,0,1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing values. To handle missing values we're gonna compute the mean for each column and replace missing values for the corresponding mean. (Note: we could also use other statistical measurements as the median or the mode for exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.nanmean(data, axis = 0)\n",
    "for i in range(1,data.shape[1]):\n",
    "  column = data[:, i]\n",
    "  mean = means[i]\n",
    "\n",
    "  data[:,i] = np.where(np.isnan(column), mean, column)\n",
    "\n",
    "for i in range(1,data.shape[1]):\n",
    "  column = test[:, i]\n",
    "  mean = means[i]\n",
    "\n",
    "  test[:,i] = np.where(np.isnan(column), mean, column)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the probability of loan default, in this dataset, we don't have the probability but instead a binary feature. To predict this probability we're gonna train a binary logistic regression model and we'll use the confidence score given by the sigmoid as the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "data_features = np.delete(data,0,1)\n",
    "data_labels = data[:,0]\n",
    "\n",
    "test_features = np.delete(test,0,1)\n",
    "\n",
    "# Create an instance of our model\n",
    "logisticRegr = LogisticRegression(max_iter=400)\n",
    "logisticRegr.fit(data_features, data_labels)\n",
    "pred = logisticRegr.predict_proba(test_features)\n",
    "pred = pred[:,1]\n",
    "indexes=np.arange(1, 101504).astype(int)\n",
    "print(indexes)\n",
    "result = np.vstack((indexes, pred)).T\n",
    "\n",
    "print(result)\n",
    "\n",
    "np.savetxt(\"array.csv\", result, delimiter=\",\",fmt=\"%g\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation with target feature(probability of loan default)\n",
    "We're gonna calculate the correlation between our target feature and each one of the resting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Correlations\n",
    "correlation_vector=np.zeros(data_features.shape[1])\n",
    "\n",
    "for i in range(0,data_features.shape[1]):\n",
    "    corr=np.corrcoef(data_features[:, 0], data_features[:, i])\n",
    "    correlation_vector[i]=corr[0,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
